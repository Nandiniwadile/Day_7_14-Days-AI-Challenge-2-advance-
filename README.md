ğŸ“… Day 7 â€“ MLflow Experiment Tracking
ğŸš€ 14 Days AI Challenge

Platform: Databricks
Tool Used: MLflow
Model: Random Forest Classifier

ğŸ“Œ Objective

Implemented MLflow to:

Log experiment runs

Track parameters

Record evaluation metrics

Save trained model

ğŸ“Š Step 1 â€“ Data Preparation

Created Spark DataFrame

Generated feature vector using VectorAssembler

Split data into train and test sets

ğŸŒ² Step 2 â€“ Model Training

Trained RandomForestClassifier

Used features column for prediction

Built binary classification model

ğŸ“ˆ Step 3 â€“ Model Evaluation

Used BinaryClassificationEvaluator

Metric: Area Under ROC Curve (AUC)

Achieved AUC Score: 1.0

ğŸ” Step 4 â€“ MLflow Tracking

Started MLflow run

Logged parameter: model_type = RandomForest

Logged metric: AUC

Logged Spark model artifact

ğŸ¯ Key Learnings

Experiment tracking is essential in production ML

MLflow helps compare and manage multiple runs

Logging models makes deployment easier

